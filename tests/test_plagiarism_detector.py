#!/usr/bin/env python3
"""
–¢–µ—Å—Ç—ã –¥–ª—è –º–æ–¥—É–ª—è plagiarism_detector –∏–∑ –ø–∞–ø–∫–∏ src
"""

import unittest
import sys
import os
import tempfile
import shutil
from pathlib import Path

# ============================================================================
# –ù–ê–°–¢–†–û–ô–ö–ê –ü–£–¢–ï–ô –î–õ–Ø –ò–ú–ü–û–†–¢–ê
# ============================================================================

# –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞
project_root = Path(__file__).parent.parent

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å Python
src_path = project_root / "src"
if src_path.exists():
    sys.path.insert(0, str(src_path))
    sys.path.insert(0, str(project_root))
    print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω –ø—É—Ç—å –∫ src: {src_path}")
else:
    print(f"‚ùå –ü–∞–ø–∫–∞ src –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {src_path}")

# ============================================================================
# –ò–ú–ü–û–†–¢ –ú–û–î–£–õ–Ø
# ============================================================================

try:
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª—å –Ω–∞–ø—Ä—è–º—É—é
    import plagiarism_detector

    MODULE_LOADED = True
    print("‚úÖ –ú–æ–¥—É–ª—å plagiarism_detector —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤
    if hasattr(plagiarism_detector, "PlagiarismDetector"):
        PlagiarismDetector = plagiarism_detector.PlagiarismDetector
        print("‚úÖ –ö–ª–∞—Å—Å PlagiarismDetector –Ω–∞–π–¥–µ–Ω")
    else:
        print("‚ùå –ö–ª–∞—Å—Å PlagiarismDetector –Ω–µ –Ω–∞–π–¥–µ–Ω")
        MODULE_LOADED = False

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ—É–Ω–∫—Ü–∏–π
    if hasattr(plagiarism_detector, "create_test_documents"):
        create_test_documents = plagiarism_detector.create_test_documents
        print("‚úÖ –§—É–Ω–∫—Ü–∏—è create_test_documents –Ω–∞–π–¥–µ–Ω–∞")
    else:
        print("‚ö†Ô∏è –§—É–Ω–∫—Ü–∏—è create_test_documents –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        create_test_documents = None

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ Document (–º–æ–∂–µ—Ç –Ω–µ –±—ã—Ç—å)
    if hasattr(plagiarism_detector, "Document"):
        Document = plagiarism_detector.Document
        print("‚úÖ –ö–ª–∞—Å—Å Document –Ω–∞–π–¥–µ–Ω")
        DOCUMENT_AVAILABLE = True
    else:
        print("‚ö†Ô∏è –ö–ª–∞—Å—Å Document –Ω–µ –Ω–∞–π–¥–µ–Ω (—ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ)")
        Document = None
        DOCUMENT_AVAILABLE = False

except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
    MODULE_LOADED = False
    PlagiarismDetector = None
    Document = None
    create_test_documents = None
    DOCUMENT_AVAILABLE = False


# ============================================================================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ============================================================================


def create_test_files(folder_path, files_dict):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤.

    Args:
        folder_path: –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ
        files_dict: —Å–ª–æ–≤–∞—Ä—å {–∏–º—è_—Ñ–∞–π–ª–∞: —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ}
    """
    folder = Path(folder_path)
    folder.mkdir(parents=True, exist_ok=True)

    for filename, content in files_dict.items():
        file_path = folder / filename
        file_path.write_text(content, encoding="utf-8")

    return folder


def cleanup_folder(folder_path):
    """–û—á–∏—Å—Ç–∫–∞ –ø–∞–ø–∫–∏."""
    if os.path.exists(folder_path):
        shutil.rmtree(folder_path)


# ============================================================================
# –¢–ï–°–¢–û–í–´–ï –ö–õ–ê–°–°–´
# ============================================================================


class TestModuleImport(unittest.TestCase):
    """–¢–µ—Å—Ç—ã –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥—É–ª—è."""

    def test_module_import(self):
        """–¢–µ—Å—Ç –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª—è."""
        self.assertTrue(MODULE_LOADED, "–ú–æ–¥—É–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω")

    def test_plagiarism_detector_class(self):
        """–¢–µ—Å—Ç –Ω–∞–ª–∏—á–∏—è –∫–ª–∞—Å—Å–∞ PlagiarismDetector."""
        self.assertIsNotNone(PlagiarismDetector, "–ö–ª–∞—Å—Å PlagiarismDetector –Ω–µ –Ω–∞–π–¥–µ–Ω")


class TestPlagiarismDetectorInitialization(unittest.TestCase):
    """–¢–µ—Å—Ç—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ PlagiarismDetector."""

    @unittest.skipIf(not MODULE_LOADED, "–ú–æ–¥—É–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω")
    def test_default_initialization(self):
        """–¢–µ—Å—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é."""
        detector = PlagiarismDetector()

        self.assertIsInstance(detector, PlagiarismDetector)
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
        self.assertTrue(hasattr(detector, "min_threshold"))
        self.assertTrue(hasattr(detector, "documents"))

    @unittest.skipIf(not MODULE_LOADED, "–ú–æ–¥—É–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω")
    def test_custom_initialization(self):
        """–¢–µ—Å—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏."""
        detector = PlagiarismDetector(min_similarity_threshold=0.5)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø–æ—Ä–æ–≥ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
        self.assertEqual(detector.min_threshold, 0.5)


class TestFileLoading(unittest.TestCase):
    """–¢–µ—Å—Ç—ã –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤."""

    @unittest.skipIf(not MODULE_LOADED, "–ú–æ–¥—É–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω")
    def setUp(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –ø–µ—Ä–µ–¥ –∫–∞–∂–¥—ã–º —Ç–µ—Å—Ç–æ–º."""
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É –¥–ª—è —Ç–µ—Å—Ç–æ–≤
        self.temp_dir = tempfile.mkdtemp(prefix="plagiarism_test_")
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
        self.test_files = {
            "doc1.txt": 
            "Artificial intelligence is transforming " "modern education.",
            "doc2.txt": 
            "AI technologies are revolutionizing " "educational systems.",
            "doc3.txt": 
            "This is a test content. " "Machine learning is important.",
        }

        self.test_folder = create_test_files(self.temp_dir, self.test_files)

        # –°–æ–∑–¥–∞–µ–º –¥–µ—Ç–µ–∫—Ç–æ—Ä
        self.detector = PlagiarismDetector()

    def tearDown(self):
        """–û—á–∏—Å—Ç–∫–∞ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —Ç–µ—Å—Ç–∞."""
        cleanup_folder(self.temp_dir)

    def test_load_valid_files(self):
        """–¢–µ—Å—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤."""
        self.detector.load_documents(str(self.test_folder))

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã
        self.assertTrue(hasattr(self.detector, "documents"))

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        # –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ø–∏—Å–æ–∫ –∏–ª–∏ –¥—Ä—É–≥–æ–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
        if hasattr(self.detector.documents, "__len__"):
            self.assertEqual(len(self.detector.documents), 3)
        else:
            # –ò–ª–∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥—Ä—É–≥–∏–º —Å–ø–æ—Å–æ–±–æ–º
            self.assertTrue(True)  # –ü—Ä–æ—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–µ—Ç –æ—à–∏–±–æ–∫

    def test_load_empty_folder(self):
        """–¢–µ—Å—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ –ø—É—Å—Ç–æ–π –ø–∞–ø–∫–∏."""
        empty_folder = self.test_folder / "empty"
        empty_folder.mkdir(exist_ok=True)

        detector = PlagiarismDetector()
        detector.load_documents(str(empty_folder))

        # –î–æ–ª–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å—Å—è 0 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        if hasattr(detector.documents, "__len__"):
            self.assertEqual(len(detector.documents), 0)

    def test_load_nonexistent_folder(self):
        """–¢–µ—Å—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –ø–∞–ø–∫–∏."""
        detector = PlagiarismDetector()

        # –î–æ–ª–∂–Ω–æ –≤—ã–∑—ã–≤–∞—Ç—å –∏—Å–∫–ª—é—á–µ–Ω–∏–µ
        with self.assertRaises(Exception):
            detector.load_documents("/nonexistent/folder/path")


class TestTextPreprocessing(unittest.TestCase):
    """–¢–µ—Å—Ç—ã –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞."""

    @unittest.skipIf(not MODULE_LOADED, "–ú–æ–¥—É–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω")
    def setUp(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–µ–¥ —Ç–µ—Å—Ç–∞–º–∏."""
        self.detector = PlagiarismDetector()

    def test_preprocess_basic(self):
        """–¢–µ—Å—Ç –±–∞–∑–æ–≤–æ–π –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –º–µ—Ç–æ–¥ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        self.assertTrue(hasattr(self.detector, "preprocess_text"))

        test_text = "Hello World! This is a TEST."
        processed = self.detector.preprocess_text(test_text)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è —Å—Ç—Ä–æ–∫–∞
        self.assertIsInstance(processed, str)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä
        self.assertEqual(processed, processed.lower())

    def test_preprocess_empty_text(self):
        """–¢–µ—Å—Ç –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—É—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."""
        processed = self.detector.preprocess_text("")
        self.assertEqual(processed, "")

        processed = self.detector.preprocess_text("   ")
        self.assertTrue(isinstance(processed, str))

    def test_preprocess_special_characters(self):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤."""
        test_text = "Multiple   spaces   here"
        processed = self.detector.preprocess_text(test_text)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–µ–ª–æ–≤
        if "   " in processed:
            # –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–ø—É—Å—Ç–∏–º–æ –≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è—Ö
            pass
        self.assertIsInstance(processed, str)


class TestSimilarityMethods(unittest.TestCase):
    """–¢–µ—Å—Ç—ã –º–µ—Ç–æ–¥–æ–≤ —Ä–∞—Å—á–µ—Ç–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏."""

    @unittest.skipIf(not MODULE_LOADED, "–ú–æ–¥—É–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω")
    def setUp(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–µ–¥ —Ç–µ—Å—Ç–∞–º–∏."""
        self.detector = PlagiarismDetector()

    def test_cosine_similarity_exists(self):
        """–¢–µ—Å—Ç —á—Ç–æ –º–µ—Ç–æ–¥ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."""
        self.assertTrue(hasattr(self.detector, "cosine_similarity_method"))

    def test_cosine_similarity_identical(self):
        """–¢–µ—Å—Ç –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ –¥–ª—è –∏–¥–µ–Ω—Ç–∏—á–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤."""
        text1 = "artificial intelligence machine learning"
        text2 = "artificial intelligence machine learning"

        similarity = self.detector.cosine_similarity_method(text1, text2)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è —á–∏—Å–ª–æ
        self.assertIsInstance(similarity, (int, float))

        # –ò–¥–µ–Ω—Ç–∏—á–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å –≤—ã—Å–æ–∫—É—é —Å—Ö–æ–∂–µ—Å—Ç—å
        self.assertGreaterEqual(similarity, 0.9)
        self.assertLessEqual(similarity, 1.0)

    def test_cosine_similarity_range(self):
        """–¢–µ—Å—Ç —á—Ç–æ —Å—Ö–æ–∂–µ—Å—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ 0-1."""
        text1 = "python programming"
        text2 = "data science"

        similarity = self.detector.cosine_similarity_method(text1, text2)

        self.assertGreaterEqual(similarity, 0.0)
        self.assertLessEqual(similarity, 1.0)

    def test_lcs_method_exists(self):
        """–¢–µ—Å—Ç —á—Ç–æ –º–µ—Ç–æ–¥ LCS —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."""
        self.assertTrue(hasattr(self.detector, "longest_common_subsequence"))

    def test_lcs_similarity(self):
        """–¢–µ—Å—Ç –º–µ—Ç–æ–¥–∞ LCS."""
        text1 = "the quick brown fox"
        text2 = "the quick brown fox"

        similarity = self.detector.longest_common_subsequence(text1, text2)

        self.assertIsInstance(similarity, (int, float))
        self.assertGreaterEqual(similarity, 0.0)
        self.assertLessEqual(similarity, 1.0)

    def test_ngram_method_exists(self):
        """–¢–µ—Å—Ç —á—Ç–æ –º–µ—Ç–æ–¥ N-gram —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."""
        self.assertTrue(hasattr(self.detector, "ngram_similarity"))

    def test_ngram_similarity(self):
        """–¢–µ—Å—Ç –º–µ—Ç–æ–¥–∞ N-gram."""
        text1 = "natural language processing"
        text2 = "natural language processing"

        similarity = self.detector.ngram_similarity(text1, text2, n=2)

        self.assertIsInstance(similarity, (int, float))
        self.assertGreaterEqual(similarity, 0.0)
        self.assertLessEqual(similarity, 1.0)


class TestFullWorkflow(unittest.TestCase):
    """–¢–µ—Å—Ç—ã –ø–æ–ª–Ω–æ–≥–æ —Ä–∞–±–æ—á–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞."""

    @unittest.skipIf(not MODULE_LOADED, "–ú–æ–¥—É–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω")
    def setUp(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."""
        self.temp_dir = tempfile.mkdtemp(prefix="plagiarism_workflow_")

        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        self.test_files = {
            "doc1.txt": "Artificial intelligence is transforming education.",
            "doc2.txt": "AI is changing the way we learn and teach.",
            "doc3.txt": "Machine learning algorithms analyze data.",
        }

        self.test_folder = create_test_files(self.temp_dir, self.test_files)
        self.detector = PlagiarismDetector(min_similarity_threshold=0.3)

    def tearDown(self):
        """–û—á–∏—Å—Ç–∫–∞ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —Ç–µ—Å—Ç–∞."""
        cleanup_folder(self.temp_dir)

    def test_load_and_process(self):
        """–¢–µ—Å—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –º–µ—Ç–æ–¥—ã —Å—É—â–µ—Å—Ç–≤—É—é—Ç
        self.assertTrue(hasattr(self.detector, "load_documents"))
        self.assertTrue(hasattr(self.detector, "process_all_documents"))

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
        self.detector.load_documents(str(self.test_folder))

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
        self.detector.process_all_documents()

        # –ï—Å–ª–∏ –Ω–µ—Ç –æ—à–∏–±–æ–∫ - —Ç–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω
        self.assertTrue(True)

    def test_calculate_similarity_matrix(self):
        """–¢–µ—Å—Ç —Ä–∞—Å—á–µ—Ç–∞ –º–∞—Ç—Ä–∏—Ü—ã —Å—Ö–æ–∂–µ—Å—Ç–∏."""
        self.assertTrue(hasattr(self.detector, "calculate_similarity_matrix"))

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
        self.detector.load_documents(str(self.test_folder))
        self.detector.process_all_documents()

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É
        result = self.detector.calculate_similarity_matrix()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —á—Ç–æ-—Ç–æ –≤–µ—Ä–Ω—É–ª–æ—Å—å
        self.assertIsNotNone(result)

        # –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä—å –∏–ª–∏ –¥—Ä—É–≥–æ–π –æ–±—ä–µ–∫—Ç
        self.assertTrue(isinstance(result, (dict, list, type(None))))

    def test_run_analysis_method(self):
        """–¢–µ—Å—Ç –º–µ—Ç–æ–¥–∞ run_analysis –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."""
        if hasattr(self.detector, "run_analysis"):
            result = self.detector.run_analysis(str(self.test_folder))

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —á—Ç–æ-—Ç–æ –≤–µ—Ä–Ω—É–ª–æ—Å—å
            self.assertIsNotNone(result)
        else:
            # –ú–µ—Ç–æ–¥ –º–æ–∂–µ—Ç –Ω–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ
            self.skipTest("–ú–µ—Ç–æ–¥ run_analysis –Ω–µ –Ω–∞–π–¥–µ–Ω")


class TestEdgeCases(unittest.TestCase):
    """–¢–µ—Å—Ç—ã –≥—Ä–∞–Ω–∏—á–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤."""

    @unittest.skipIf(not MODULE_LOADED, "–ú–æ–¥—É–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω")
    def setUp(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–µ–¥ —Ç–µ—Å—Ç–∞–º–∏."""
        self.detector = PlagiarismDetector()

    def test_similarity_with_empty_texts(self):
        """–¢–µ—Å—Ç —Å—Ö–æ–∂–µ—Å—Ç–∏ —Å –ø—É—Å—Ç—ã–º–∏ —Ç–µ–∫—Å—Ç–∞–º–∏."""
        # –ö–æ—Å–∏–Ω—É—Å–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å
        cosine = self.detector.cosine_similarity_method("", "test")
        self.assertIsInstance(cosine, (int, float))

        cosine = self.detector.cosine_similarity_method("", "")
        self.assertIsInstance(cosine, (int, float))

    def test_long_text_processing(self):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª–∏–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."""
        long_text = "word " * 100

        processed = self.detector.preprocess_text(long_text)
        self.assertIsInstance(processed, str)
        self.assertTrue(len(processed) > 0)

    def test_unicode_text(self):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ Unicode —Ç–µ–∫—Å—Ç–∞."""
        test_texts = [
            "–ü—Ä–∏–≤–µ—Ç –º–∏—Ä",  # –†—É—Å—Å–∫–∏–π
            "Hello world",  # –ê–Ω–≥–ª–∏–π—Å–∫–∏–π
            "123 numbers",  # –¶–∏—Ñ—Ä—ã
            "Test with symbols !@#$%",  # –°–∏–º–≤–æ–ª—ã
        ]

        for text in test_texts:
            processed = self.detector.preprocess_text(text)
            self.assertIsInstance(processed, str)
            # –ù–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∏—Å–∫–ª—é—á–µ–Ω–∏–π


class TestCreateTestDocuments(unittest.TestCase):
    """–¢–µ—Å—Ç—ã —Ñ—É–Ω–∫—Ü–∏–∏ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."""

    @unittest.skipIf(
        not MODULE_LOADED or create_test_documents is None,
        "–§—É–Ω–∫—Ü–∏—è create_test_documents –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞",
    )
    def test_create_test_documents(self):
        """–¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."""
        temp_dir = tempfile.mkdtemp(prefix="test_docs_")

        try:
            # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
            result = create_test_documents(temp_dir)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø–∞–ø–∫–∞ —Å–æ–∑–¥–∞–Ω–∞
            self.assertTrue(os.path.exists(temp_dir))

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ
            files = list(Path(temp_dir).glob("*"))
            self.assertGreater(len(files), 0)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–π–ª—ã —Å–æ–¥–µ—Ä–∂–∞—Ç —Ç–µ–∫—Å—Ç
            for file_path in files:
                content = file_path.read_text(encoding="utf-8")
                self.assertGreater(len(content), 0)

        finally:
            cleanup_folder(temp_dir)


# ============================================================================
# –ó–ê–ü–£–°–ö –¢–ï–°–¢–û–í
# ============================================================================


def run_selected_tests():
    """–ó–∞–ø—É—Å–∫ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤ (–±–µ–∑ —Ç—Ä–µ–±—É—é—â–∏—Ö Document)."""
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä
    test_loader = unittest.TestLoader()

    # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –∫–ª–∞—Å—Å—ã –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —Ç—Ä–µ–±—É—é—Ç Document
    test_suite = unittest.TestSuite()

    if MODULE_LOADED:
        test_classes = [
            TestModuleImport,
            TestPlagiarismDetectorInitialization,
            TestFileLoading,
            TestTextPreprocessing,
            TestSimilarityMethods,
            TestFullWorkflow,
            TestEdgeCases,
        ]

        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –µ—Å–ª–∏ —Ñ—É–Ω–∫—Ü–∏—è –¥–æ—Å—Ç—É–ø–Ω–∞
        if create_test_documents is not None:
            test_classes.append(TestCreateTestDocuments)

        for test_class in test_classes:
            test_suite.addTests(test_loader.loadTestsFromTestCase(test_class))
    else:
        print("\n‚ö†Ô∏è –ú–æ–¥—É–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω, –∑–∞–ø—É—Å–∫–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—ã–µ —Ç–µ—Å—Ç—ã")
        test_suite.addTests(test_loader.loadTestsFromTestCase(TestModuleImport))

    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)

    # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print("\n" + "=" * 60)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–û–í:")
    print(f"  –í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤: {result.testsRun}")
    success_count = result.testsRun - len(result.failures) - len(result.errors)
    print(f"  –£—Å–ø–µ—à–Ω–æ: {success_count}")

    if result.failures:
        print(f"  –ü—Ä–æ–≤–∞–ª–µ–Ω–æ: {len(result.failures)}")

    if result.errors:
        print(f"  –û—à–∏–±–æ–∫: {len(result.errors)}")

    print("=" * 60)

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª–∏ –µ—Å–ª–∏ –µ—Å—Ç—å –æ—à–∏–±–∫–∏
    if result.failures or result.errors:
        print("\nüîç –î–ï–¢–ê–õ–ò –û–®–ò–ë–û–ö:")
        for test, traceback in result.failures + result.errors:
            print(f"\n‚ùå {test}:")
            print("-" * 40)
            print(traceback)

    return result.wasSuccessful()


if __name__ == "__main__":
    print("\n" + "=" * 60)
    print("üß™ –¢–ï–°–¢–´ –î–õ–Ø PLAGIARISM DETECTOR (–±–µ–∑ –∫–ª–∞—Å—Å–∞ Document)")
    print("=" * 60)

    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
    success = run_selected_tests()

    # –ó–∞–≤–µ—Ä—à–∞–µ–º —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º –∫–æ–¥–æ–º –≤—ã—Ö–æ–¥–∞
    sys.exit(0 if success else 1)
