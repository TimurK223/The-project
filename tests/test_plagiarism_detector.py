#!/usr/bin/env python3
"""
–û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è —Å–∏—Å—Ç–µ–º—ã –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –ø–ª–∞–≥–∏–∞—Ç–∞

–°–æ–¥–µ—Ä–∂–∏—Ç –º–æ–¥—É–ª—å–Ω—ã–µ –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏:
1. –û—Å–Ω–æ–≤–Ω–æ–≥–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞ PlagiarismDetector
2. –†–µ–∂–∏–º–∞ —Ä–∞–±–æ—Ç—ã —Å –æ—Ç–¥–µ–ª—å–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏
3. –£—Ç–∏–ª–∏—Ç
4. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
"""

import unittest
import tempfile
import shutil
import os
from pathlib import Path
import json

# –ò–º–ø–æ—Ä—Ç —Ç–µ—Å—Ç–∏—Ä—É–µ–º—ã—Ö –º–æ–¥—É–ª–µ–π
try:
    from src import PlagiarismDetector, setup_environment, compare_specific_files
    from src.plagiarism_detector import create_test_documents, create_test_documents_english
    from src.single_file_mode import compare_folder_with_reference
    MODULES_AVAILABLE = True
except ImportError as e:
    print(f"‚ö†Ô∏è Warning: Could not import main modules: {e}")
    MODULES_AVAILABLE = False

# –ò–º–ø–æ—Ä—Ç —Ç–µ—Å—Ç–æ–≤—ã—Ö —É—Ç–∏–ª–∏—Ç
from tests import (
    create_test_file,
    create_sample_texts,
    compare_results,
    assert_similarity_range,
    cleanup_test_files,
    TEST_DATA_DIR,
    TEST_OUTPUT_DIR
)

class TestBasicFunctionality(unittest.TestCase):
    """–¢–µ—Å—Ç—ã –±–∞–∑–æ–≤–æ–≥–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞"""
    
    @classmethod
    def setUpClass(cls):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–µ–¥ –≤—Å–µ–º–∏ —Ç–µ—Å—Ç–∞–º–∏ –∫–ª–∞—Å—Å–∞"""
        if not MODULES_AVAILABLE:
            raise unittest.SkipTest("Main modules not available")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        cls.test_data = create_sample_texts()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–π –ø–∞–ø–∫–∏ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
        cls.test_folder = TEST_DATA_DIR / "basic_test"
        cls.test_folder.mkdir(exist_ok=True)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤
        for i, (name, content) in enumerate(cls.test_data.items()):
            file_path = cls.test_folder / f"{name}.txt"
            file_path.write_text(content, encoding='utf-8')
    
    @classmethod
    def tearDownClass(cls):
        """–û—á–∏—Å—Ç–∫–∞ –ø–æ—Å–ª–µ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤ –∫–ª–∞—Å—Å–∞"""
        # –£–¥–∞–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –ø–∞–ø–∫—É
        if cls.test_folder.exists():
            shutil.rmtree(cls.test_folder)
    
    def setUp(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–µ–¥ –∫–∞–∂–¥—ã–º —Ç–µ—Å—Ç–æ–º"""
        self.detector = PlagiarismDetector(min_similarity_threshold=0.3)
    
    def test_detector_initialization(self):
        """–¢–µ—Å—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞"""
        self.assertIsNotNone(self.detector)
        self.assertEqual(self.detector.min_threshold, 0.3)
        self.assertIsInstance(self.detector.documents, list)
    
    def test_load_documents(self):
        """–¢–µ—Å—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        self.detector.load_documents(str(self.test_folder))
        
        self.assertEqual(len(self.detector.documents), len(self.test_data))
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ —Ñ–∞–π–ª—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã
        loaded_filenames = [doc.filename for doc in self.detector.documents]
        expected_filenames = [f"{name}.txt" for name in self.test_data.keys()]
        
        for expected in expected_filenames:
            self.assertIn(expected, loaded_filenames)
    
    def test_text_preprocessing(self):
        """–¢–µ—Å—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞"""
        test_text = "Hello World! This is a TEST with numbers 123."
        processed = self.detector.preprocess_text(test_text)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ç–µ–∫—Å—Ç –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
        self.assertEqual(processed, processed.lower())
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
        self.assertNotIn('!', processed)
        self.assertNotIn('123', processed)
    
    def test_empty_document_handling(self):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—É—Å—Ç—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
            f.write("")
            empty_file = f.name
        
        try:
            # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª
            temp_dir = tempfile.mkdtemp()
            shutil.move(empty_file, os.path.join(temp_dir, "empty.txt"))
            
            detector = PlagiarismDetector()
            detector.load_documents(temp_dir)
            
            # –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω, –Ω–æ —Å –ø—É—Å—Ç—ã–º —Å–æ–¥–µ—Ä–∂–∏–º—ã–º
            self.assertEqual(len(detector.documents), 1)
            
        finally:
            # –û—á–∏—Å—Ç–∫–∞
            if os.path.exists(temp_dir):
                shutil.rmtree(temp_dir)

class TestSimilarityMethods(unittest.TestCase):
    """–¢–µ—Å—Ç—ã –º–µ—Ç–æ–¥–æ–≤ —Ä–∞—Å—á–µ—Ç–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏"""
    
    def test_cosine_similarity(self):
        """–¢–µ—Å—Ç –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞"""
        if not MODULES_AVAILABLE:
            self.skipTest("Main modules not available")
        
        detector = PlagiarismDetector()
        
        # –ò–¥–µ–Ω—Ç–∏—á–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã
        text1 = "artificial intelligence is changing the world"
        text2 = "artificial intelligence is changing the world"
        similarity = detector.cosine_similarity_method(text1, text2)
        self.assertAlmostEqual(similarity, 1.0, places=2)
        
        # –°–æ–≤–µ—Ä—à–µ–Ω–Ω–æ —Ä–∞–∑–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã
        text3 = "machine learning algorithms"
        text4 = "quantum physics experiments"
        similarity = detector.cosine_similarity_method(text3, text4)
        self.assertLess(similarity, 0.3)
        
        # –ß–∞—Å—Ç–∏—á–Ω–æ –ø–æ—Ö–æ–∂–∏–µ —Ç–µ–∫—Å—Ç—ã
        text5 = "deep learning neural networks for image recognition"
        text6 = "neural networks and deep learning algorithms"
        similarity = detector.cosine_similarity_method(text5, text6)
        self.assertGreater(similarity, 0.5)
        self.assertLess(similarity, 1.0)
    
    def test_lcs_similarity(self):
        """–¢–µ—Å—Ç –º–µ—Ç–æ–¥–∞ LCS"""
        if not MODULES_AVAILABLE:
            self.skipTest("Main modules not available")
        
        detector = PlagiarismDetector()
        
        # –ò–¥–µ–Ω—Ç–∏—á–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        text1 = "the quick brown fox jumps over the lazy dog"
        text2 = "the quick brown fox jumps over the lazy dog"
        similarity = detector.longest_common_subsequence(text1, text2)
        self.assertAlmostEqual(similarity, 1.0, places=2)
        
        # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        text3 = "artificial intelligence and machine learning"
        text4 = "machine learning and artificial intelligence"
        similarity = detector.longest_common_subsequence(text3, text4)
        self.assertGreater(similarity, 0.5)
        
        # –†–∞–∑–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã
        text5 = "hello world python programming"
        text6 = "data science artificial intelligence"
        similarity = detector.longest_common_subsequence(text5, text6)
        self.assertEqual(similarity, 0.0)
    
    def test_ngram_similarity(self):
        """–¢–µ—Å—Ç –º–µ—Ç–æ–¥–∞ N-gram"""
        if not MODULES_AVAILABLE:
            self.skipTest("Main modules not available")
        
        detector = PlagiarismDetector()
        
        # –ò–¥–µ–Ω—Ç–∏—á–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã
        text1 = "natural language processing is interesting"
        text2 = "natural language processing is interesting"
        similarity = detector.ngram_similarity(text1, text2, n=2)
        self.assertAlmostEqual(similarity, 1.0, places=2)
        
        # –° —Ä–∞–∑–Ω—ã–º n
        text3 = "machine learning deep learning"
        text4 = "deep learning machine learning"
        
        similarity_n2 = detector.ngram_similarity(text3, text4, n=2)
        similarity_n3 = detector.ngram_similarity(text3, text4, n=3)
        
        self.assertNotEqual(similarity_n2, similarity_n3)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–Ω–∏—á–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤
        similarity_empty = detector.ngram_similarity("", "test", n=2)
        self.assertEqual(similarity_empty, 0.0)

class TestSingleFileMode(unittest.TestCase):
    """–¢–µ—Å—Ç—ã —Ä–µ–∂–∏–º–∞ —Ä–∞–±–æ—Ç—ã —Å –æ—Ç–¥–µ–ª—å–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏"""
    
    def setUp(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–µ–¥ –∫–∞–∂–¥—ã–º —Ç–µ—Å—Ç–æ–º"""
        if not MODULES_AVAILABLE:
            self.skipTest("Main modules not available")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤
        self.test_files = []
        
        # –§–∞–π–ª 1: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç
        self.file1 = TEST_DATA_DIR / "original.txt"
        self.file1.write_text(
            "Artificial intelligence is transforming modern education "
            "through personalized learning systems.",
            encoding='utf-8'
        )
        self.test_files.append(str(self.file1))
        
        # –§–∞–π–ª 2: –ü–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (–ø–ª–∞–≥–∏–∞—Ç)
        self.file2 = TEST_DATA_DIR / "paraphrased.txt"
        self.file2.write_text(
            "AI technologies are revolutionizing education by enabling "
            "personalized learning approaches.",
            encoding='utf-8'
        )
        self.test_files.append(str(self.file2))
        
        # –§–∞–π–ª 3: –°–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –¥—Ä—É–≥–æ–π —Ç–µ–∫—Å—Ç
        self.file3 = TEST_DATA_DIR / "different.txt"
        self.file3.write_text(
            "Quantum computing uses quantum bits to perform calculations "
            "much faster than classical computers.",
            encoding='utf-8'
        )
        self.test_files.append(str(self.file3))
    
    def tearDown(self):
        """–û—á–∏—Å—Ç–∫–∞ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —Ç–µ—Å—Ç–∞"""
        # –§–∞–π–ª—ã —É–¥–∞–ª—è—é—Ç—Å—è –≤ cleanup
        pass
    
    def test_compare_specific_files(self):
        """–¢–µ—Å—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        results = compare_specific_files(self.test_files)
        
        self.assertIsNotNone(results)
        self.assertIn('combined_matrix', str(results))
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–¥–µ—Ä–∂–∞—Ç –Ω—É–∂–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        if isinstance(results, dict):
            self.assertIn('filenames', results)
            self.assertEqual(len(results.get('filenames', [])), 3)
    
    def test_compare_folder_with_reference(self):
        """–¢–µ—Å—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø–∞–ø–∫–∏ —Å —ç—Ç–∞–ª–æ–Ω–æ–º"""
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
        test_folder = TEST_DATA_DIR / "folder_test"
        test_folder.mkdir(exist_ok=True)
        
        # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫—É (–∫—Ä–æ–º–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç —ç—Ç–∞–ª–æ–Ω–æ–º)
        shutil.copy2(str(self.file2), str(test_folder / "student1.txt"))
        shutil.copy2(str(self.file3), str(test_folder / "student2.txt"))
        
        try:
            results = compare_folder_with_reference(
                reference_file=str(self.file1),
                folder_path=str(test_folder)
            )
            
            self.assertIsNotNone(results)
            
            # –î–æ–ª–∂–Ω—ã –±—ã—Ç—å 3 –¥–æ–∫—É–º–µ–Ω—Ç–∞ (—ç—Ç–∞–ª–æ–Ω + 2 —Å—Ç—É–¥–µ–Ω—á–µ—Å–∫–∏—Ö)
            if isinstance(results, dict) and 'filenames' in results:
                self.assertEqual(len(results['filenames']), 3)
                
        finally:
            # –û—á–∏—Å—Ç–∫–∞
            if test_folder.exists():
                shutil.rmtree(test_folder)
    
    def test_single_file_mode_invalid_input(self):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ–≤–µ—Ä–Ω–æ–≥–æ –≤–≤–æ–¥–∞"""
        # –ù–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª
        results = compare_specific_files(["nonexistent.txt", "another_fake.txt"])
        self.assertIsNone(results)
        
        # –¢–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ñ–∞–π–ª
        results = compare_specific_files([str(self.file1)])
        self.assertIsNone(results)
        
        # –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫
        results = compare_specific_files([])
        self.assertIsNone(results)

class TestIntegration(unittest.TestCase):
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã"""
    
    def test_full_workflow(self):
        """–¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ —Ä–∞–±–æ—á–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞"""
        if not MODULES_AVAILABLE:
            self.skipTest("Main modules not available")
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        test_folder = TEST_DATA_DIR / "workflow_test"
        create_test_documents(str(test_folder))
        
        try:
            # –°–æ–∑–¥–∞–µ–º –¥–µ—Ç–µ–∫—Ç–æ—Ä
            detector = PlagiarismDetector(
                min_similarity_threshold=0.3,
                language='russian'
            )
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
            detector.load_documents(str(test_folder))
            self.assertGreater(len(detector.documents), 0)
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
            detector.process_all_documents()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
            for doc in detector.documents:
                self.assertTrue(doc.processed_content)
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å
            results = detector.calculate_similarity_matrix()
            
            self.assertIsNotNone(results)
            self.assertIn('combined', results)
            self.assertIn('filenames', results)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
            detector.generate_report(results)
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è (–ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–µ –ø–∞–¥–∞–µ—Ç)
            try:
                detector.visualize_results(results)
                visualization_exists = (TEST_OUTPUT_DIR / "similarity_matrix.png").exists() or \
                                      Path("similarity_matrix.png").exists()
                self.assertTrue(visualization_exists)
            except Exception as e:
                print(f"Visualization warning: {e}")
                # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–∂–µ—Ç –ø–∞–¥–∞—Ç—å –∏–∑-–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
            
        finally:
            # –û—á–∏—Å—Ç–∫–∞
            if test_folder.exists():
                shutil.rmtree(test_folder)

class TestEdgeCases(unittest.TestCase):
    """–¢–µ—Å—Ç—ã –≥—Ä–∞–Ω–∏—á–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤"""
    
    def test_large_files(self):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤"""
        if not MODULES_AVAILABLE:
            self.skipTest("Main modules not available")
        
        # –°–æ–∑–¥–∞–µ–º –±–æ–ª—å—à–æ–π —Ñ–∞–π–ª
        large_file = TEST_DATA_DIR / "large.txt"
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –±–æ–ª—å—à–æ–π —Ç–µ–∫—Å—Ç (–æ–∫–æ–ª–æ 1MB)
        large_text = "Sample sentence. " * 50000
        
        with open(large_file, 'w', encoding='utf-8') as f:
            f.write(large_text)
        
        try:
            detector = PlagiarismDetector()
            
            # –î–æ–ª–∂–µ–Ω –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ –æ—à–∏–±–æ–∫
            processed = detector.preprocess_text(large_text)
            self.assertIsInstance(processed, str)
            self.assertLess(len(processed), len(large_text))  # –ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ—Ä–æ—á–µ
            
        finally:
            if large_file.exists():
                large_file.unlink()
    
    def test_special_characters(self):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        if not MODULES_AVAILABLE:
            self.skipTest("Main modules not available")
        
        detector = PlagiarismDetector()
        
        test_cases = [
            ("Hello ¬© World ¬Æ", "hello world"),
            ("Text with emoji üòÄ üëç", "text with emoji"),
            ("HTML entities &lt;div&gt;", "html entities lt div gt"),
            ("Multiple   spaces   here", "multiple spaces here"),
            ("Line\nbreaks\nhere", "line breaks here"),
            ("Mixed CASE TeXt", "mixed case text"),
        ]
        
        for input_text, expected_clean in test_cases:
            processed = detector.preprocess_text(input_text)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–∂–∏–¥–∞–µ–º—ã–µ —Å–ª–æ–≤–∞
            for word in expected_clean.split():
                if word:  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
                    self.assertIn(word, processed)
    
    def test_different_languages(self):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–æ–≤"""
        if not MODULES_AVAILABLE:
            self.skipTest("Main modules not available")
        
        # –†—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç
        detector_ru = PlagiarismDetector(language='russian')
        text_ru = "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –º–µ–Ω—è–µ—Ç –º–∏—Ä"
        processed_ru = detector_ru.preprocess_text(text_ru)
        
        self.assertIsInstance(processed_ru, str)
        self.assertEqual(processed_ru, processed_ru.lower())
        
        # –ê–Ω–≥–ª–∏–π—Å–∫–∏–π —Ç–µ–∫—Å—Ç
        detector_en = PlagiarismDetector(language='english')
        text_en = "Artificial Intelligence is changing the world"
        processed_en = detector_en.preprocess_text(text_en)
        
        self.assertIsInstance(processed_en, str)
        self.assertEqual(processed_en, processed_en.lower())
        
        # –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ (–¥–æ–ª–∂–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å –¥–ª—è –æ–±–æ–∏—Ö)
        detector_auto = PlagiarismDetector(language='auto')
        processed_auto_ru = detector_auto.preprocess_text(text_ru)
        processed_auto_en = detector_auto.preprocess_text(text_en)
        
        self.assertTrue(processed_auto_ru)
        self.assertTrue(processed_auto_en)

class TestPerformance(unittest.TestCase):
    """–¢–µ—Å—Ç—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    
    def test_similarity_calculation_speed(self):
        """–¢–µ—Å—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏ —Ä–∞—Å—á–µ—Ç–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏"""
        if not MODULES_AVAILABLE:
            self.skipTest("Main modules not available")
        
        import time
        
        detector = PlagiarismDetector()
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ —Ç–µ–∫—Å—Ç—ã
        text1 = " ".join(["word"] * 100)  # 100 —Å–ª–æ–≤
        text2 = " ".join(["word"] * 100)  # –ò–¥–µ–Ω—Ç–∏—á–Ω—ã–π —Ç–µ–∫—Å—Ç
        
        # –ò–∑–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        start_time = time.time()
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        for _ in range(10):
            similarity = detector.cosine_similarity_method(text1, text2)
            self.assertAlmostEqual(similarity, 1.0, places=2)
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –Ω–µ —Å–ª–∏—à–∫–æ–º –¥–æ–ª–≥–æ–µ
        # (10 –æ–ø–µ—Ä–∞—Ü–∏–π –¥–æ–ª–∂–Ω—ã –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è –º–µ–Ω–µ–µ —á–µ–º –∑–∞ 5 —Å–µ–∫—É–Ω–¥)
        self.assertLess(execution_time, 5.0)
        
        print(f"\n‚è± Similarity calculation time: {execution_time:.3f} seconds for 10 operations")

def run_tests():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤"""
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    from tests import setup_test_environment
    setup_test_environment()
    
    # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
    loader = unittest.TestLoader()
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ç–µ—Å—Ç—ã
    test_suite = unittest.TestSuite()
    
    test_suite.addTests(loader.loadTestsFromTestCase(TestBasicFunctionality))
    test_suite.addTests(loader.loadTestsFromTestCase(TestSimilarityMethods))
    test_suite.addTests(loader.loadTestsFromTestCase(TestSingleFileMode))
    test_suite.addTests(loader.loadTestsFromTestCase(TestIntegration))
    test_suite.addTests(loader.loadTestsFromTestCase(TestEdgeCases))
    test_suite.addTests(loader.loadTestsFromTestCase(TestPerformance))
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    # –û—á–∏—Å—Ç–∫–∞
    from tests import teardown_test_environment
    teardown_test_environment()
    
    return result.wasSuccessful()

if __name__ == '__main__':
    # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ –ø—Ä–∏ –ø—Ä—è–º–æ–º –≤—ã–∑–æ–≤–µ
    success = run_tests()
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–¥ –≤—ã—Ö–æ–¥–∞
    import sys
    sys.exit(0 if success else 1)
