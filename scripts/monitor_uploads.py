#!/usr/bin/env python3
"""
–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞–ø–∫–∏ uploads/ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –∑–∞–ø—É—Å–∫–æ–º –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–æ–≤
"""

import os
import sys
import time
import json
import shutil
import logging
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

try:
    from src import PlagiarismDetector, setup_environment, get_supported_formats

    MODULE_LOADED = True
except ImportError:
    MODULE_LOADED = False
    print("‚ùå –ú–æ–¥—É–ª—å src –Ω–µ –Ω–∞–π–¥–µ–Ω. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞.")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
UPLOADS_DIR = project_root / "uploads"
RESULTS_DIR = project_root / "results"
PROCESSED_DIR = project_root / "processed"
LOG_FILE = project_root / "monitor.log"

# –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
UPLOADS_DIR.mkdir(exist_ok=True)
RESULTS_DIR.mkdir(exist_ok=True)
PROCESSED_DIR.mkdir(exist_ok=True)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.FileHandler(LOG_FILE), logging.StreamHandler(sys.stdout)],
)
logger = logging.getLogger(__name__)


class UploadHandler(FileSystemEventHandler):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–±—ã—Ç–∏–π —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –¥–ª—è –ø–∞–ø–∫–∏ uploads/"""

    def __init__(self, detector: Optional[PlagiarismDetector] = None):
        super().__init__()
        self.detector = detector
        self.processing_files = set()
        self.delay = 5  # –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –∞–Ω–∞–ª–∏–∑–æ–º (—Å–µ–∫—É–Ω–¥—ã)

    def on_created(self, event):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–±—ã—Ç–∏—è —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–∞"""
        if event.is_directory:
            return

        file_path = Path(event.src_path)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
        supported_formats = get_supported_formats() if MODULE_LOADED else [".txt"]
        if file_path.suffix.lower() not in supported_formats:
            logger.info(f"–§–∞–π–ª {file_path.name} –∏–º–µ–µ—Ç –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç")
            return

        logger.info(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω –Ω–æ–≤—ã–π —Ñ–∞–π–ª: {file_path.name}")

        # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–π–ª –≤ –æ–±—Ä–∞–±–æ—Ç–∫—É
        self.processing_files.add(str(file_path))

        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –∑–∞–¥–µ—Ä–∂–∫—É
        time.sleep(self.delay)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –≤—Å–µ –µ—â–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if file_path.exists():
            self.process_file(file_path)
        else:
            logger.warning(f"–§–∞–π–ª {file_path.name} –±—ã–ª —É–¥–∞–ª–µ–Ω –ø–µ—Ä–µ–¥ –∞–Ω–∞–ª–∏–∑–æ–º")

    def on_modified(self, event):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–±—ã—Ç–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞ (–µ—Å–ª–∏ —Ñ–∞–π–ª –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è —á–∞—Å—Ç—è–º–∏)"""
        if event.is_directory:
            return

        file_path = Path(event.src_path)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
        supported_formats = get_supported_formats() if MODULE_LOADED else [".txt"]
        if file_path.suffix.lower() not in supported_formats:
            return

        # –ï—Å–ª–∏ —Ñ–∞–π–ª —É–∂–µ –≤ –æ–±—Ä–∞–±–æ—Ç–∫–µ, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º
        if str(file_path) in self.processing_files:
            return

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        if file_path.stat().st_size > 100 * 1024 * 1024:  # 100MB
            logger.warning(
                f"–§–∞–π–ª {file_path.name} —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (>{file_path.stat().st_size/1024/1024:.1f}MB)"
            )
            return

        logger.info(f"–§–∞–π–ª –∏–∑–º–µ–Ω–µ–Ω: {file_path.name}")

        # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –¥–ª—è –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        time.sleep(2)

        if file_path.exists():
            self.processing_files.add(str(file_path))
            self.process_file(file_path)

    def process_file(self, file_path: Path):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ - –∑–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞: {file_path.name}")

            if not self.detector:
                logger.error("–î–µ—Ç–µ–∫—Ç–æ—Ä –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
                return

            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            temp_dir = UPLOADS_DIR / "temp_analysis"
            temp_dir.mkdir(exist_ok=True)

            # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É
            temp_file = temp_dir / file_path.name
            shutil.copy2(file_path, temp_file)

            # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
            results = self.detector.run_analysis(str(temp_dir))

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            self.save_results(file_path.name, results)

            # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ñ–∞–π–ª
            self.move_processed_file(file_path)

            # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É
            shutil.rmtree(temp_dir)

            logger.info(f"–ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞ {file_path.name} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file_path.name}: {e}")

        finally:
            # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª –∏–∑ —Å–ø–∏—Å–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            if str(file_path) in self.processing_files:
                self.processing_files.remove(str(file_path))

    def save_results(self, filename: str, results: Dict):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –≤ JSON —Å timestamp"""
        try:
            # –°–æ–∑–¥–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ —Å timestamp
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            result_filename = f"analysis_{filename}_{timestamp}.json"
            result_path = RESULTS_DIR / result_filename

            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            results_with_metadata = {
                "metadata": {
                    "original_file": filename,
                    "analysis_timestamp": datetime.now().isoformat(),
                    "analysis_duration": results.get("analysis_duration", 0),
                    "system_version": "1.0.0",
                },
                "analysis": results,
            }

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON
            with open(result_path, "w", encoding="utf-8") as f:
                json.dump(
                    results_with_metadata, f, ensure_ascii=False, indent=2, default=str
                )

            logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {result_path}")

            # –¢–∞–∫–∂–µ —Å–æ–∑–¥–∞–µ–º –∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á–µ—Ç
            self.create_summary_report(filename, results)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")

    def create_summary_report(self, filename: str, results: Dict):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫—Ä–∞—Ç–∫–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –≤ CSV"""
        try:
            csv_path = RESULTS_DIR / f"summary_{datetime.now().strftime('%Y%m%d')}.csv"

            # –ï—Å–ª–∏ —Ñ–∞–π–ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —á–∏—Ç–∞–µ–º –µ–≥–æ
            if csv_path.exists():
                import pandas as pd

                df = pd.read_csv(csv_path)
            else:
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π DataFrame
                import pandas as pd

                df = pd.DataFrame(
                    columns=[
                        "timestamp",
                        "filename",
                        "total_documents",
                        "potential_cases",
                        "max_similarity",
                        "avg_similarity",
                    ]
                )

            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å
            new_row = {
                "timestamp": datetime.now().isoformat(),
                "filename": filename,
                "total_documents": results.get("summary", {}).get("total_documents", 0),
                "potential_cases": results.get("summary", {}).get(
                    "potential_plagiarism_cases", 0
                ),
                "max_similarity": results.get("summary", {}).get("max_similarity", 0),
                "avg_similarity": results.get("summary", {}).get("avg_similarity", 0),
            }

            # –î–æ–±–∞–≤–ª—è–µ–º –≤ DataFrame –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
            df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)
            df.to_csv(csv_path, index=False, encoding="utf-8")

        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å CSV –æ—Ç—á–µ—Ç: {e}")

    def move_processed_file(self, file_path: Path):
        """–ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –≤ –ø–∞–ø–∫—É processed"""
        try:
            # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–ø–∞–ø–∫—É —Å –¥–∞—Ç–æ–π
            date_folder = PROCESSED_DIR / datetime.now().strftime("%Y-%m-%d")
            date_folder.mkdir(exist_ok=True)

            # –ù–æ–≤–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ —Å timestamp
            timestamp = datetime.now().strftime("%H%M%S")
            new_filename = f"{file_path.stem}_{timestamp}{file_path.suffix}"
            new_path = date_folder / new_filename

            # –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ñ–∞–π–ª
            shutil.move(file_path, new_path)
            logger.info(f"–§–∞–π–ª –ø–µ—Ä–µ–º–µ—â–µ–Ω –≤: {new_path}")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")


def check_existing_files(uploads_dir: Path) -> List[Path]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ uploads"""
    existing_files = []
    for file_path in uploads_dir.glob("*"):
        if file_path.is_file():
            supported_formats = get_supported_formats() if MODULE_LOADED else [".txt"]
            if file_path.suffix.lower() in supported_formats:
                existing_files.append(file_path)

    return existing_files


def initialize_detector() -> Optional[PlagiarismDetector]:
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –ø–ª–∞–≥–∏–∞—Ç–∞"""
    try:
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è
        setup_environment()

        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞
        detector = PlagiarismDetector(min_similarity_threshold=0.3, language="auto")

        logger.info("–î–µ—Ç–µ–∫—Ç–æ—Ä –ø–ª–∞–≥–∏–∞—Ç–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return detector

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞: {e}")
        return None


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
    print("\n" + "=" * 60)
    print("üìÅ –ú–û–ù–ò–¢–û–†–ò–ù–ì –ü–ê–ü–ö–ò UPLOADS/")
    print("=" * 60)

    if not MODULE_LOADED:
        print("‚ùå –ú–æ–¥—É–ª—å src –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
        return

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞
    detector = initialize_detector()
    if not detector:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–µ—Ç–µ–∫—Ç–æ—Ä")
        return

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã
    print(f"üìÇ –ü–∞–ø–∫–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–æ–∫: {UPLOADS_DIR}")
    existing_files = check_existing_files(UPLOADS_DIR)

    if existing_files:
        print(f"üìã –ù–∞–π–¥–µ–Ω–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤: {len(existing_files)}")
        for file_path in existing_files:
            print(f"  - {file_path.name}")

        # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã
        response = input("\nüìä –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã? (y/n): ")
        if response.lower() == "y":
            for file_path in existing_files:
                handler = UploadHandler(detector)
                handler.process_file(file_path)

    # –°–æ–∑–¥–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–±—ã—Ç–∏–π
    event_handler = UploadHandler(detector)

    # –°–æ–∑–¥–∞–µ–º –Ω–∞–±–ª—é–¥–∞—Ç–µ–ª—å
    observer = Observer()
    observer.schedule(event_handler, str(UPLOADS_DIR), recursive=False)

    print("\nüöÄ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–∞–ø—É—â–µ–Ω...")
    print(f"üìÅ –ü–∞–ø–∫–∞: {UPLOADS_DIR}")
    print("üìä –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–æ–≤")
    print("üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ –ø–∞–ø–∫—É results/")
    print("üõë –î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞–∂–º–∏—Ç–µ Ctrl+C\n")

    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
        observer.start()

        # –ë–µ—Å–∫–æ–Ω–µ—á–Ω—ã–π —Ü–∏–∫–ª
        while True:
            time.sleep(1)

    except KeyboardInterrupt:
        print("\n\nüõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞...")

    finally:
        observer.stop()
        observer.join()
        print("‚úÖ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")


if __name__ == "__main__":
    main()
